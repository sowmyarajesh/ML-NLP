{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenize_NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMl737fQEPR73VsgbMNDTgW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sowmyarajesh/ML-NLP/blob/main/NLTK_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB1aQa-EEQG2",
        "outputId": "8d3e291d-198a-4166-9e0b-eedd05c4f08e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "import nltk.corpus\n",
        "from nltk.tokenize import word_tokenize\n",
        "'''\n",
        "punkt is a nltk library tool for tokenizing text documents. \n",
        "When we use an old or a degraded version of nltk module we generally need to download the remaining data .\n",
        "'''\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('corpus')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampleString = \"Mr. [**Known lastname 3234**] is a 36 year old gentleman with a PMH signifciant with dilated cardiomyopathy s/p AICD, asthma, and HTN admitted to an OSH with dyspnea now admitted to the MICU after PEA arrest x2.\"\n",
        "sample_tokens = word_tokenize(sampleString)\n",
        "sample_tokens\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kJTZLgxGaSg",
        "outputId": "cc12b7f5-e1fc-46f6-c948-268c9892e2e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mr.',\n",
              " '[',\n",
              " '*',\n",
              " '*',\n",
              " 'Known',\n",
              " 'lastname',\n",
              " '3234',\n",
              " '*',\n",
              " '*',\n",
              " ']',\n",
              " 'is',\n",
              " 'a',\n",
              " '36',\n",
              " 'year',\n",
              " 'old',\n",
              " 'gentleman',\n",
              " 'with',\n",
              " 'a',\n",
              " 'PMH',\n",
              " 'signifciant',\n",
              " 'with',\n",
              " 'dilated',\n",
              " 'cardiomyopathy',\n",
              " 's/p',\n",
              " 'AICD',\n",
              " ',',\n",
              " 'asthma',\n",
              " ',',\n",
              " 'and',\n",
              " 'HTN',\n",
              " 'admitted',\n",
              " 'to',\n",
              " 'an',\n",
              " 'OSH',\n",
              " 'with',\n",
              " 'dyspnea',\n",
              " 'now',\n",
              " 'admitted',\n",
              " 'to',\n",
              " 'the',\n",
              " 'MICU',\n",
              " 'after',\n",
              " 'PEA',\n",
              " 'arrest',\n",
              " 'x2',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(sample_tokens), len(sample_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBowGgycG2bs",
        "outputId": "76ab2cd9-0c7b-4d93-8e46-0db4284b8239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 46)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# frequency of tokens\n",
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist()\n",
        "for i in sample_tokens:\n",
        "  fdist[i] = fdist[i]+1\n",
        "\n",
        "fdist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynJ5TlPrHqH_",
        "outputId": "e076d246-4710-4f66-bfc2-cb4505d31592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'*': 4,\n",
              "          ',': 2,\n",
              "          '.': 1,\n",
              "          '3234': 1,\n",
              "          '36': 1,\n",
              "          'AICD': 1,\n",
              "          'HTN': 1,\n",
              "          'Known': 1,\n",
              "          'MICU': 1,\n",
              "          'Mr.': 1,\n",
              "          'OSH': 1,\n",
              "          'PEA': 1,\n",
              "          'PMH': 1,\n",
              "          '[': 1,\n",
              "          ']': 1,\n",
              "          'a': 2,\n",
              "          'admitted': 2,\n",
              "          'after': 1,\n",
              "          'an': 1,\n",
              "          'and': 1,\n",
              "          'arrest': 1,\n",
              "          'asthma': 1,\n",
              "          'cardiomyopathy': 1,\n",
              "          'dilated': 1,\n",
              "          'dyspnea': 1,\n",
              "          'gentleman': 1,\n",
              "          'is': 1,\n",
              "          'lastname': 1,\n",
              "          'now': 1,\n",
              "          'old': 1,\n",
              "          's/p': 1,\n",
              "          'signifciant': 1,\n",
              "          'the': 1,\n",
              "          'to': 2,\n",
              "          'with': 3,\n",
              "          'x2': 1,\n",
              "          'year': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the top 10  words\n",
        "top_10_words = fdist.most_common(10)\n",
        "top_10_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl2TDA5TIAOs",
        "outputId": "4e5b0042-e9bb-4803-9a5e-217cae6b3fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('*', 4),\n",
              " ('with', 3),\n",
              " ('a', 2),\n",
              " (',', 2),\n",
              " ('admitted', 2),\n",
              " ('to', 2),\n",
              " ('Mr.', 1),\n",
              " ('[', 1),\n",
              " ('Known', 1),\n",
              " ('lastname', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bi-grams"
      ],
      "metadata": {
        "id": "nsiHuHc1JaFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.bigrams(sample_tokens)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-Umu33XIL1q",
        "outputId": "bf2416d5-d9f4-4c96-befe-a3ed9ff47042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mr.', '['),\n",
              " ('[', '*'),\n",
              " ('*', '*'),\n",
              " ('*', 'Known'),\n",
              " ('Known', 'lastname'),\n",
              " ('lastname', '3234'),\n",
              " ('3234', '*'),\n",
              " ('*', '*'),\n",
              " ('*', ']'),\n",
              " (']', 'is'),\n",
              " ('is', 'a'),\n",
              " ('a', '36'),\n",
              " ('36', 'year'),\n",
              " ('year', 'old'),\n",
              " ('old', 'gentleman'),\n",
              " ('gentleman', 'with'),\n",
              " ('with', 'a'),\n",
              " ('a', 'PMH'),\n",
              " ('PMH', 'signifciant'),\n",
              " ('signifciant', 'with'),\n",
              " ('with', 'dilated'),\n",
              " ('dilated', 'cardiomyopathy'),\n",
              " ('cardiomyopathy', 's/p'),\n",
              " ('s/p', 'AICD'),\n",
              " ('AICD', ','),\n",
              " (',', 'asthma'),\n",
              " ('asthma', ','),\n",
              " (',', 'and'),\n",
              " ('and', 'HTN'),\n",
              " ('HTN', 'admitted'),\n",
              " ('admitted', 'to'),\n",
              " ('to', 'an'),\n",
              " ('an', 'OSH'),\n",
              " ('OSH', 'with'),\n",
              " ('with', 'dyspnea'),\n",
              " ('dyspnea', 'now'),\n",
              " ('now', 'admitted'),\n",
              " ('admitted', 'to'),\n",
              " ('to', 'the'),\n",
              " ('the', 'MICU'),\n",
              " ('MICU', 'after'),\n",
              " ('after', 'PEA'),\n",
              " ('PEA', 'arrest'),\n",
              " ('arrest', 'x2'),\n",
              " ('x2', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.trigrams(sample_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuY_CmXMJjGC",
        "outputId": "3a375a29-e9b8-4693-a5bc-9eb276aaa9a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mr.', '[', '*'),\n",
              " ('[', '*', '*'),\n",
              " ('*', '*', 'Known'),\n",
              " ('*', 'Known', 'lastname'),\n",
              " ('Known', 'lastname', '3234'),\n",
              " ('lastname', '3234', '*'),\n",
              " ('3234', '*', '*'),\n",
              " ('*', '*', ']'),\n",
              " ('*', ']', 'is'),\n",
              " (']', 'is', 'a'),\n",
              " ('is', 'a', '36'),\n",
              " ('a', '36', 'year'),\n",
              " ('36', 'year', 'old'),\n",
              " ('year', 'old', 'gentleman'),\n",
              " ('old', 'gentleman', 'with'),\n",
              " ('gentleman', 'with', 'a'),\n",
              " ('with', 'a', 'PMH'),\n",
              " ('a', 'PMH', 'signifciant'),\n",
              " ('PMH', 'signifciant', 'with'),\n",
              " ('signifciant', 'with', 'dilated'),\n",
              " ('with', 'dilated', 'cardiomyopathy'),\n",
              " ('dilated', 'cardiomyopathy', 's/p'),\n",
              " ('cardiomyopathy', 's/p', 'AICD'),\n",
              " ('s/p', 'AICD', ','),\n",
              " ('AICD', ',', 'asthma'),\n",
              " (',', 'asthma', ','),\n",
              " ('asthma', ',', 'and'),\n",
              " (',', 'and', 'HTN'),\n",
              " ('and', 'HTN', 'admitted'),\n",
              " ('HTN', 'admitted', 'to'),\n",
              " ('admitted', 'to', 'an'),\n",
              " ('to', 'an', 'OSH'),\n",
              " ('an', 'OSH', 'with'),\n",
              " ('OSH', 'with', 'dyspnea'),\n",
              " ('with', 'dyspnea', 'now'),\n",
              " ('dyspnea', 'now', 'admitted'),\n",
              " ('now', 'admitted', 'to'),\n",
              " ('admitted', 'to', 'the'),\n",
              " ('to', 'the', 'MICU'),\n",
              " ('the', 'MICU', 'after'),\n",
              " ('MICU', 'after', 'PEA'),\n",
              " ('after', 'PEA', 'arrest'),\n",
              " ('PEA', 'arrest', 'x2'),\n",
              " ('arrest', 'x2', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.ngrams(sample_tokens,5))"
      ],
      "metadata": {
        "id": "KCbnJcRyJmF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b56a4ad2-414d-4362-fb62-a078450f2b77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mr.', '[', '*', '*', 'Known'),\n",
              " ('[', '*', '*', 'Known', 'lastname'),\n",
              " ('*', '*', 'Known', 'lastname', '3234'),\n",
              " ('*', 'Known', 'lastname', '3234', '*'),\n",
              " ('Known', 'lastname', '3234', '*', '*'),\n",
              " ('lastname', '3234', '*', '*', ']'),\n",
              " ('3234', '*', '*', ']', 'is'),\n",
              " ('*', '*', ']', 'is', 'a'),\n",
              " ('*', ']', 'is', 'a', '36'),\n",
              " (']', 'is', 'a', '36', 'year'),\n",
              " ('is', 'a', '36', 'year', 'old'),\n",
              " ('a', '36', 'year', 'old', 'gentleman'),\n",
              " ('36', 'year', 'old', 'gentleman', 'with'),\n",
              " ('year', 'old', 'gentleman', 'with', 'a'),\n",
              " ('old', 'gentleman', 'with', 'a', 'PMH'),\n",
              " ('gentleman', 'with', 'a', 'PMH', 'signifciant'),\n",
              " ('with', 'a', 'PMH', 'signifciant', 'with'),\n",
              " ('a', 'PMH', 'signifciant', 'with', 'dilated'),\n",
              " ('PMH', 'signifciant', 'with', 'dilated', 'cardiomyopathy'),\n",
              " ('signifciant', 'with', 'dilated', 'cardiomyopathy', 's/p'),\n",
              " ('with', 'dilated', 'cardiomyopathy', 's/p', 'AICD'),\n",
              " ('dilated', 'cardiomyopathy', 's/p', 'AICD', ','),\n",
              " ('cardiomyopathy', 's/p', 'AICD', ',', 'asthma'),\n",
              " ('s/p', 'AICD', ',', 'asthma', ','),\n",
              " ('AICD', ',', 'asthma', ',', 'and'),\n",
              " (',', 'asthma', ',', 'and', 'HTN'),\n",
              " ('asthma', ',', 'and', 'HTN', 'admitted'),\n",
              " (',', 'and', 'HTN', 'admitted', 'to'),\n",
              " ('and', 'HTN', 'admitted', 'to', 'an'),\n",
              " ('HTN', 'admitted', 'to', 'an', 'OSH'),\n",
              " ('admitted', 'to', 'an', 'OSH', 'with'),\n",
              " ('to', 'an', 'OSH', 'with', 'dyspnea'),\n",
              " ('an', 'OSH', 'with', 'dyspnea', 'now'),\n",
              " ('OSH', 'with', 'dyspnea', 'now', 'admitted'),\n",
              " ('with', 'dyspnea', 'now', 'admitted', 'to'),\n",
              " ('dyspnea', 'now', 'admitted', 'to', 'the'),\n",
              " ('now', 'admitted', 'to', 'the', 'MICU'),\n",
              " ('admitted', 'to', 'the', 'MICU', 'after'),\n",
              " ('to', 'the', 'MICU', 'after', 'PEA'),\n",
              " ('the', 'MICU', 'after', 'PEA', 'arrest'),\n",
              " ('MICU', 'after', 'PEA', 'arrest', 'x2'),\n",
              " ('after', 'PEA', 'arrest', 'x2', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "There are many stemming algorithm in nltk. We will try PorterStemming here."
      ],
      "metadata": {
        "id": "ooMSvHzqJ73X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "pst = PorterStemmer()\n",
        "pst.stem(\"winning\"), pst.stem(\"studies\"), pst.stem(\"buying\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TPSF5OqJ1jP",
        "outputId": "41b05736-44ba-4f66-c988-14c29ce128b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('win', 'studi', 'buy')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "JyP4xQvLLWTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsLQaUjNMvyh",
        "outputId": "71c2cc86-566a-4899-fafa-b782708ece53"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer, wordnet\n",
        "lem = WordNetLemmatizer()\n",
        "words = [\"cats\", \"cacti\", \"tooths\"]\n",
        "for w in words:\n",
        "  print(w +\" => \"+lem.lemmatize(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5fPCmSTLNLR",
        "outputId": "7b9e60ce-306b-4e49-b6c3-22800277aac2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats => cat\n",
            "cacti => cactus\n",
            "tooths => tooth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# parts of speech tagging"
      ],
      "metadata": {
        "id": "-C2Zu0EiNXr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IncrLhgaOiob",
        "outputId": "65e872e2-1309-4401-ca87-6f06579697d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampleText = \"What is the best way to say I like icecream\"\n",
        "sToken = word_tokenize(sampleText)\n",
        "for s in sToken:\n",
        "  print(nltk.pos_tag([s]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afXqmcKKMmzf",
        "outputId": "177752fb-3b39-4252-f4ab-5cf4fad3777d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('What', 'WP')]\n",
            "[('is', 'VBZ')]\n",
            "[('the', 'DT')]\n",
            "[('best', 'JJS')]\n",
            "[('way', 'NN')]\n",
            "[('to', 'TO')]\n",
            "[('say', 'VB')]\n",
            "[('I', 'PRP')]\n",
            "[('like', 'IN')]\n",
            "[('icecream', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampleText = \"Marry had a little lamb. she loves it\"\n",
        "sToken = word_tokenize(sampleText)\n",
        "for s in sToken:\n",
        "  print(nltk.pos_tag([s]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z4pRkO_OPzE",
        "outputId": "1519d3e6-a3dd-4144-f5f7-074cd63f8efd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Marry', 'NN')]\n",
            "[('had', 'VBD')]\n",
            "[('a', 'DT')]\n",
            "[('little', 'JJ')]\n",
            "[('lamb', 'NN')]\n",
            "[('.', '.')]\n",
            "[('she', 'PRP')]\n",
            "[('loves', 'NNS')]\n",
            "[('it', 'PRP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# name entity recognition"
      ],
      "metadata": {
        "id": "7jlk00dUPmGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05_RmkM-QQDk",
        "outputId": "9c30992c-d424-4b28-db76-4a95a9ee56f1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ne_chunk\n",
        "sampleText = \"Google opens a billion dollar investment in New York\"\n",
        "sToken = word_tokenize(sampleText)\n",
        "sTags =nltk.pos_tag(sToken)\n",
        "sNER = ne_chunk(sTags)\n",
        "print(sTags)\n",
        "print(sNER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U5O18cNO6Fd",
        "outputId": "d8b745cf-a7c9-4532-b22e-ddf6fbcbb7d3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Google', 'NNP'), ('opens', 'VBZ'), ('a', 'DT'), ('billion', 'CD'), ('dollar', 'NN'), ('investment', 'NN'), ('in', 'IN'), ('New', 'NNP'), ('York', 'NNP')]\n",
            "(S\n",
            "  (GPE Google/NNP)\n",
            "  opens/VBZ\n",
            "  a/DT\n",
            "  billion/CD\n",
            "  dollar/NN\n",
            "  investment/NN\n",
            "  in/IN\n",
            "  (GPE New/NNP York/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "02ydrlK4QNgG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}